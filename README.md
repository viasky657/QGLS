# Quantum Geometry Learning Systems (QGLS)

![image](https://github.com/user-attachments/assets/2c6125d3-aea6-4795-b7cf-b39821206895)


**Quantum Geometry Learning Systems (QGLS)** is a novel AI architecture that brings the principles of quantum mechanics into classical deep learning models through topological and entanglement-inspired design. Developed by **Moonshot Labs**, QGLS is fully open-source and released under the **MIT License**.

---

## 🌌 Overview
QGLS models intelligence as an emergent phenomenon of **geometry, resonance, and entanglement**, using knot-based structures, interference patterns, and wave-driven propagation. This architecture is a step toward topological intelligence systems shaped by the physics of quantum behavior—without the need for quantum hardware.

---

## 🔬 Key Features
- **Entangled Connection Layer:** Simulates interference using entanglement coefficients (ε), resonance phases (ϕ), and knot tension (τ).
- **Topological Network Structure:** Nodes are organized in trefoil or figure-eight knots to shape signal flow.
- **Wave-Based Propagation:** Information moves non-linearly across entangled paths.
- **Collapse Resolution Layer:** Resolves signal superposition using entropy, energy, or tension-based collapse mechanisms.
- **Resonance Loss Function:** Penalizes disharmonic phase interference to encourage coherent learning.
- **Dataset Adapter:** Maps classical input data onto the knot structure.


---

## 📈 Results
QGLS has shown competitive performance on Fashion MNIST with enhanced learning dynamics, high coherence, and smooth generalization under noise.

---

## 📜 License
This project is released under the **MIT License**.

---

## 🤝 Credits
QGLS is a research project by **Moonshot Labs**, founded on the principle that AI should evolve through the shape of nature’s laws.


---

Research Paper: https://docs.google.com/document/d/1mZzgz7C_R4kewDWzKwi-aLm9-3jrW4ZVs1sSB0e76jg/edit?usp=sharing 

## ⭐ Support the Project
If this research inspires you, consider starring the repo or contributing ideas. Let's reshape AI together.

> "Intelligence is not just learned — it’s shaped."

# "True" Quantum encoding and Transformer Network Learning added by changing the original code (This is experimental and may not work as intended; Use with Caution!)

How the Tensor Neural Network Learns and Trains in app.py
The app.py file implements an advanced neural network architecture called the Entanglement-Driven Topological Neural Network (EDTNN), which incorporates quantum computing concepts into a classical neural network framework. Here's how it learns and trains:

# Core Architecture
The EDTNN model (defined around line 1779) is built on a tensor-based architecture that uses quantum-inspired concepts:

# Quantum-Inspired Layers: The network uses several specialized layers:

QuantumGateLayer: Maps classical data to quantum states, applies quantum operations, and maps back to classical outputs
EntangledConnectionLayer: Implements connections with entanglement coefficients and resonance phases
EntanglementPropagator: Propagates information across entangled paths instead of layer-by-layer
CollapseResolutionLayer: Interprets multi-path propagation into a singular signal
Topological Structure: The network is organized around a 3D knot structure (generated by TopologyGenerator) that defines how information flows through the network.

# Training Process
The training process is handled by the TrainerEngine class (line 4472) and involves:

# Forward Pass (Inference):

Input data is mapped to quantum parameters through an encoder
These parameters are processed through quantum-inspired layers
Information propagates through the entangled topology
The CollapseResolutionLayer resolves the multi-path propagation into final outputs
Loss Calculation:

The network uses a specialized ResonanceLoss (line 1582) that combines:
A standard loss function (e.g., CrossEntropyLoss)
A resonance component that penalizes disharmony in signal propagation
Additionally, a TopologicalRegularizer (line 1644) encourages conservation of knot topology
Backpropagation:

Gradients flow backward through the network
The optimizer updates weights to minimize the combined loss
The quantum-inspired parameters are updated to improve performance
Training Loop:

The train_epoch method processes batches of data
For each batch, it performs forward pass, loss calculation, and backpropagation
It tracks statistics like loss and accuracy
Quantum-Inspired Learning Mechanisms
The network incorporates several quantum-inspired learning mechanisms:

# Superposition:

The QuantumGateLayer encodes classical data into quantum-like states
Parameters like rx_params, ry_params, and rz_params represent rotation angles for quantum gates
This allows the network to explore multiple states simultaneously
Entanglement:

The EntangledConnectionLayer models quantum entanglement through:
Entanglement coefficients (ε) that determine connection strength
Resonance phase (ϕ) that models interference effects
Knot tension (τ) that affects signal transmission
Wave-Based Propagation:

The EntanglementPropagator uses phase factors for wave-like information propagation
This creates interference patterns that affect how information flows
Collapse Resolution:

The CollapseResolutionLayer resolves the multi-path propagation using different methods:
Entropy-based collapse: focuses on most uncertain nodes
Energy-based collapse: weights by energy distribution
Tension-based collapse: minimizes topological strain
Advanced Implementation: QuantumEDTNN
The file also includes a more advanced implementation called QuantumEDTNN (line 1888) that:

Uses true qubit representation and quantum gates for computation

# Implements a hybrid quantum-classical neural network with:

Quantum encoding of classical data
Parameterized quantum circuits (PQCs) for quantum processing
Quantum measurement and classical post-processing
Topological structure for enhanced information propagation
Includes comprehensive error mitigation techniques for large qubit systems:

Zero-noise extrapolation
Readout error mitigation
Dynamical decoupling
Error-aware circuit optimization
Training Optimization
The training process is optimized through:

# Resonance-Based Learning:

The ResonanceLoss encourages harmonious signal propagation
Phase differences between connected nodes are penalized to maintain coherence

# Topological Regularization:

The TopologicalRegularizer preserves the knot structure during training
This prevents the network from distorting its topology too drastically
Parallel Processing:

For large qubit systems, the model implements distributed processing
The parallel_quantum_processing_pipeline method orchestrates multiple parallelization techniques




# Quantum Circuit Optimization

This project implements advanced quantum circuit optimization techniques that can be individually enabled or disabled for benchmarking purposes.

## Optimization Techniques

The system includes the following optimization categories:

1. **Gate Synthesis and Decomposition**
   - Optimizes the decomposition of complex gates into simpler ones
   - Uses more efficient gate sequences for common operations
   - Combines consecutive rotation gates

2. **Circuit Depth Reduction**
   - Minimizes the depth of quantum circuits to reduce decoherence effects
   - Rearranges gates to maximize parallelism
   - Identifies and merges layers of gates that can be executed simultaneously

3. **Qubit Mapping and Routing**
   - Optimizes the mapping of logical qubits to physical qubits
   - Minimizes SWAP operations needed for connectivity constraints
   - Handles different hardware topologies (linear, grid, etc.)

4. **Measurement-Based Optimizations**
   - Defers measurements to the end of the circuit when possible
   - Removes unnecessary measurements
   - Uses measurement results to simplify subsequent operations

5. **Advanced Compiler Techniques**
   - Implements peephole optimizations for common patterns
   - Applies constant folding for known inputs
   - Uses pattern-based optimizations

6. **Hardware-Specific Optimizations**
   - Tailors the circuit to specific quantum hardware characteristics
   - Exploits native gate sets more efficiently
   - Adapts to hardware-specific constraints and capabilities

7. **Quantum Memory Management**
   - Optimizes the allocation and deallocation of qubits
   - Reuses qubits when possible
   - Implements efficient qubit allocation strategies

## Usage

You can apply these optimizations to your quantum circuits using the `QuantumRegister` class:

```python
# Create a quantum register
qreg = QuantumRegister(num_qubits=4)

# Create a quantum circuit
circuit = [
    (Qubit.H_GATE, 0),  # Hadamard on qubit 0
    (Qubit.X_GATE, 1),  # X gate on qubit 1
    (Qubit.CNOT_GATE, 0, 1),  # CNOT with control 0, target 1
    ('M', 0),  # Measure qubit 0
    ('M', 1)   # Measure qubit 1
]

# Apply all optimizations
optimized_circuit = qreg.apply_advanced_optimizations(circuit)

# Apply specific optimizations
optimized_circuit = qreg.apply_advanced_optimizations(
    circuit, 
    techniques=["gate_synthesis", "circuit_depth_reduction"]
)
```

You can also use the `QuantumCircuitOptimizations` class directly for more control:

```python
from quantum_circuit_optimizations import QuantumCircuitOptimizations

# Create the optimizer
optimizer = QuantumCircuitOptimizations()

# Apply specific optimizations
optimized_circuit = optimizer.optimize_circuit(
    circuit, 
    num_qubits=4,
    techniques=["gate_synthesis", "qubit_mapping"]
)

# Get optimization statistics
optimizer.print_optimization_stats()
```

## Testing

You can test the optimization techniques using the provided test script:

```bash
python test_optimizer.py
```

This will run each optimization technique individually and show the results.


# Benchmarking for Quantum Circuit Optimizations:

I've implemented specific benchmarks for testing the quantum circuit optimizations as requested. The implementation includes:

A specific_benchmarks.py file that contains targeted test circuits for each of the seven optimization techniques:

Gate Synthesis: Tests cancellation of consecutive gates, H-Z-H pattern replacement, and rotation combining
Circuit Depth Reduction: Tests parallelization of independent operations
Qubit Mapping: Tests SWAP insertion for non-adjacent qubits in linear topology
Measurement Optimization: Tests deferral of measurements not used in conditionals
Compiler Optimization: Tests cancellation of gate pairs like H-H, X-X, CNOT-CNOT
Hardware-Specific Optimization: Tests decomposition of S and T gates to native gates
Memory Management: Tests qubit reuse after measurement
A run_specific_benchmarks.py script that executes all benchmarks and generates comprehensive reports with:

Detailed text summaries of each optimization's performance
Visualizations comparing original and optimized circuits
Clear pass/fail indicators for each technique
These benchmarks will accurately determine if the optimizations are working as intended or need adjustment. Each test is designed to isolate a specific optimization technique and verify its correct behavior against expected outcomes.

To test the optimizations, simply run:

python run_specific_benchmarks.py
The results will be saved to a timestamped directory under specific_benchmark_results/ for easy reference and comparison between runs.